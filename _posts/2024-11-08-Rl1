---
layout: post
comments: true
title:  "Ideas on Recreating O1"
excerpt: "Part 1 of the series on understanding and reimplemeting O1, This blog I discuss and summarize the papers that might have been the backbone of O1 implementation."
date:   2024-10-31 11:00:00
mathjax: true
---
About:
Science of decision making. It's interdisciplinary, borrows ideas from various different areas of science and Mathematics, cs: ml, engineering: optimal control, neuroscience: reward system, Math: operations research, economics: bounded rationality, psychology: classical/operant conditioning. 

diff btw supervised vs reinforcement learning:
- Theres is no supervisior only rewards (-ve or +ve)
- delayed feedback and no instantaneous result
- Time really matters ( sequential and non iid data)
- unlike in other methods, here the agent's actions influence the subsequent data it receives, eg: a robot might see a different thing depending upon the direction it moves. 

Examples:
- fly stunt manoeuvres in helicopter - agent drives operates the helicopter, no intermediate checks more like the final result are rewarded.
- Defeat the world champion at backgammon. - palying the game again and again figured out the way to play better than humans.
-  managing investment portfolio
- controls a power station
- make a humanoid robot to walk. 
- play many different atari game better than humans. 

Reinforcement learning problem:
$r_{t}$ - reward, a scalar feedback signal. how well a job is done at step $t$, the agent's goal will be to maximise the overall reward. 
This take is bit controversial, because people may not always agree to this premise, the all task can be reward oriented. 
Reinforcement learning is based on Reward Hypothesis:

> all goals can be described by the maximisation of expected cumulative reward. 

Example rewards;
 - Fly stunt manoevers in a helicopter
	 -  $+ve$ reward for the following desired trajectory. 
	 - $-ve$ reward for crashing.
 we can do Output Reward Model(ORM), $i.e$ reward based on the final outcome alone, or Process Reward Model(PRM). 

	Goal: select actions to maximise the total future rewards.

